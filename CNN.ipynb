{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Las \"Convolutional Neural Networks - CNN\" o Redes Neuronales Convolucionales en español, son un tipo de red neuronal enfocada en el procesamieno de matrices bidimencionales, debido a esto son muy utlizadas para vision artifcial, clasificcion y segmentacion de imagenes.\n",
    "\n",
    "Las CNN, realizan en general el mismo funcionamiento de un \"Neural Network\", ya que primeramente realizan la extraccion de caracteriticas para posteriormente realizar el proceso de decision.\n",
    "\n",
    "\"Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers\"\n",
    "\n",
    "## Convolucion ##\n",
    "\n",
    "Lo relevante hablando de estas es como opera para realizar esto, pue el primer paso es realizar convoluciones.\n",
    "\n",
    "Para esto pantiemos el ejemplo de imagenes.\n",
    "\n",
    "Cada imagen \"i\" fungira como nuestra entrada, más precisamente $ I = \\{i_{1} ... i_{N} \\} $ .\n",
    "\n",
    "Una imagen es una matris bidimensional, en donde cada uno de sus elementos cuenta con un valor del 0 al 255.\n",
    "\n",
    "Y a su vez tenemos un Kernel, tambien llamado filtro una vez lo operamos sobre toda la imagen.\n",
    "\n",
    "Un kernel es una matris bidimencional, que se utliza para realizar enfoques, desenfoques, deteccion de bordes, realce, entre otras aplicaciones.\n",
    "\n",
    "\n",
    "Lo que nos es muy utili si lo que buscamos es obtener caracteristicas de una imagen.\n",
    "\n",
    "Para operar el kernel sobre una imagen es necesario realizar una convolucion entre ambos.\n",
    "\n",
    "Recordando la definicion de convolucion continua es la siguiente:\n",
    "$$ s(t) = \\int x(a)w(t-a)\\,da $$\n",
    "\n",
    "$$ s(t) = (x * w)(t) $$\n",
    "\n",
    "Donde w es funcion de dencidad de probabilidad, y w es 0 para los valores negativos\n",
    "\n",
    "Referente a nuestro problema, x es el ***input***, w es el ***kernel*** y s es lo llamado ***feauture map***\n",
    "\n",
    "Pero esta definicion de convolucion no es util para nosotros ya que nuestros datos son discretos.\n",
    "\n",
    "Para esto existe la definicion discreto de convolucion:\n",
    "$$ s(t) = (x * w)(t) = \\sum_{a=-\\infty}^{\\infty} x(a)w(t-a)$$\n",
    "\n",
    "Aun sobre esto, en esta y muchas aplicaciones de machine learning el ***input*** es una matriz multidimensional de **datos**, a su vez el ***kernel*** es una matriz multidimensional de ***parametros***, dicho esto, en terminologia adaptada para los algoritmos de aprendizaje, a estas matrices multidimensionales se les llama ***tensors***, a su vez asuminos que su valor es 0 excepto en el conjnto finito de puntos que los conforman.\n",
    "\n",
    "La razon de esta ultima, declaracion es debido a que la convolucion discreta esta definda en de $-\\infty\\ a\\ \\infty$ por lo que resultaria imposible operar con esta, sin definr el complemento del conjunto de puntos de los ***tensores***, debido a esto se definio al conjunto complemento como 0 en todos sus elemtos.\n",
    "\n",
    "Con esto en mente haremos uso de la convolucion en mas de una dimension como ejes.\n",
    "\n",
    "Para ejempleficar usando el ejemplo anterior\n",
    "$$ S(i,j) = ( I * K)(i,j) = \\sum_{m} \\sum_{n} I(m,n)K(i-m,j-n) $$\n",
    "\n",
    "$$Aplicando\\ la\\ propiedad\\ conmutativa\\ de\\ la\\ convoucion$$\n",
    "\n",
    "$$ S(i,j) = ( K * I)(i,j) = \\sum_{m} \\sum_{n} I(i-m,j-n)K(m,n) $$\n",
    "\n",
    "\n",
    "Usualmente la segunda forma es mayormente usada para la implemetacion de las bibliotecas de ML, debido a que hay menos variacion en el rango de valores validos para m y n.\n",
    "\n",
    "La propieda conmutativa de la convolucion surguio porque volteamos el kernel relativo a el input, aunque esto unicmente tiene relevancia para la imlementacion puesto qe para elanalisisde la CNN esto es irelevante.\n",
    "\n",
    "Pese a esta propiedad, muchasotras librerias hacen uso de una operacion llamada ***cross-correlation*** la cual e parecida a la convolucion, tanto que incluso es llamada de la mis forma, esta es:\n",
    "$$ S(i,j) = ( K * I)(i,j) = \\sum_{m} \\sum_{n} I(i+m,j+n)K(m,n) $$\n",
    "\n",
    "Para una representacion grafica del comportamiento de la convolucion:\n",
    "\n",
    "<div style=\"display: inline-block;\">\n",
    "<div style=\"float: left;text-align: center;width: 50%;\"> <img src=\"conv1.png\" width=\"70%\"/>  </div>\n",
    "<div style=\"float: right;text-align: center;width: 50%;position: relative;\"> <img src=\"conv2.png\" width=\"80%\"/></div>\n",
    "</div>\n",
    "La convolucion ofreceun menor numero de operaciones y una ventaja respecto a espacio, ya que debido a que la interaccion entre el **input** y el **kernel** es sumamente menor respecto a la clasica multiplicacion de matrices, y debido a que kernels pequeños reltivos al tamaño de la entrada son los utilizados el  costo respecto a almacenmiento es menor.\n",
    " \n",
    "\n",
    "### Interaccion de la red ###\n",
    "\n",
    "En las CNN uno de los principios que se sobre pone a todo es *sparce interaction* o **escas iteraccion**, esto se ve reflejado en la interaccion entre los nodos de las diferentes capas, ya que en estas la interaccion *directa* que tiene la salida de un nodo $X_{n}^{l}$ donde *l* es la capa y *n* el nodo de la dicha capa, unicamente afectara **directamente** a los nodos $X_{n-1}^{l+1}$, $X_{n}^{l+1}$ y $X_{n+1}^{l+1}$ esto pensando que el kernel tiene un ***tamaño de 3***, esto promueve la escasa interaccion.\n",
    "\n",
    "Pero debido a esto se podria a llegar a pensar \"Como obtien toda la informacion que le ofrece la entrada si la interaccion directa es tan poca\", pues la solucion a esto se plantea que se debe a la interaccion **indirecta** de los nodos, ya que el **receptive field** crece conforme las capas se vuelvan mas profunas pudiendo tener interaccion con todo los nodos.\n",
    "\n",
    "Para una representacion grafica del comportamiento de lo anterior:\n",
    "<div style=\"display: inline-block;\">\n",
    "<div style=\"float: left;text-align: center;width: 50%;\"> <img src=\"receptive_field.png\" width=\"50%\"/>  </div>\n",
    "<div style=\"float: right;text-align: center;width: 50%;\"> <img src=\"receptive_field2.png\" width=\"50%\"/>  </div>\n",
    "</div>\n",
    "\n",
    "Cabe mencionar una de las mayores ventjas tanto de la convolucion como de la escasa interaccion es que ofrece una disminusion en lasdimenciones de los datos conforme pasa atravez de las capas.\n",
    "\n",
    "### Parametros compartidos ###\n",
    "En una red neuronal regular los ***parametros de aprendizaje*** son llamados vectores de pesos, dando como resultdo una matriz de pesos por capa, donde esta matriz tiene un tamaño de $(W^{m * n})^{l}$, esto ucamente para la capa **l**, esto implica que exstiran **L** matrices para realizar las operaciones pertinentes, el problema de esto recae en el numero de usus que se le da cada peso $w_{p,q}^{l}$, ya que unicamete tienen un uso para la generacion de la salida respecto a los nodos de entrada.\n",
    "\n",
    "En las CNN esto es diferente ya que se hace uso de ***parameter sharing***, esto es debido a que, en cada capa se hace uso de un kernel (filtro), para obtener las caracteristicas necesarias, pero esto ofrece muchas ventajas entre las cuales esta que unicamente se almacena una matriz mucho mas pequeña que las anteriores.\n",
    "\n",
    "### Equivariance ###\n",
    "Debido al comportaiento particular que causa el ***parameter sharing*** en las CNN, las capas que las conforman de desarrollan una propiedad llamada ***equivariance*** a las transformaciones.\n",
    "\n",
    "Que una función es *equivariance* significa que si el *input* cambia, el *output* cambia en la misma direccion. Especificamente una $f(x)$ es *equivariance* a una funcion g, si $f(g(x)) = g(f(x))$.\n",
    "\n",
    "En el sentido de la convolucion si g es una funcion que transforma su input , f es la convulucion, x el input y k el kernel, $g(f(x,k)) = f(g(x),k)$,\n",
    "$$ si Y =  g(X * K) = g(X) * K $$\n",
    "\n",
    "La convolucion es parte unicamete de las primeras capas de las CNN, estas enfocadas a obtencion de caracteristicas\n",
    "\n",
    "## Poolling ##\n",
    "\n",
    "Para describir el comportamiento del ***poolling*** es sumamente util, primeramente describir la composicion tipica de una capa en una CNN.\n",
    "<div style=\"display: inline-block;\">\n",
    "<div style=\"text-align: center;\"> <img src=\"stages.jpeg\" width=\"35%\"/>  </div>\n",
    "</div>\n",
    "\n",
    "Una esplicacion breve sobre estas etapas seria la siguiente:\n",
    "+ Primera etapa: En esta estapa se realizan el conjunto de convoluciones a las entrada de forma paralela para producir un **conjunto de  activaciones lineares**\n",
    "+ Segunda etapa: En esta etapa cada activacion lineal es pasada atravez de una funcion de activacion no-lineal, como la funcion de activacion de rectificado lineal de su acronimo en ingles (**ReLu**)\n",
    "    $$ ReLU, f(x) = x^{+} = max(0,x)  $$\n",
    "Una vez llegando a la tercera etapa, procederemos a explicar la funcion ***poolling***, esta funcion transforma la salida del proceso anterior en una ubicacion determinada con un resumen de estadisticas de la salidas cercanas.\n",
    "\n",
    "Por ejemplo: \n",
    "El ***Max pooling*** en el resumen estadistico regresa el valor maximo de los vecinos de una area cuadrangular.\n",
    "\n",
    "Pero en lo general **poolling** ayuda a realiza una representacion aproximada **invariante** a una transformacion pequeña de lo que entro.\n",
    "\n",
    "Una transformacion invariante significa, que si transformamos el input en una pequeña cantidad, muchos de los valores resultantes de la funcion no cambiaran\n",
    "\n",
    "ya que es mas importante conocer las caracteristicas que la localizacion de ellas.\n",
    "\n",
    "<div style=\"display: inline-block;\">\n",
    "<div style=\"text-align: center;\"> <img src=\"pooling.png\" width=\"50%\"/>  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "Falta mas.....\n",
    "\n",
    "La architectura finalmente se veria de esta forma:\n",
    "\n",
    "![](./arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
